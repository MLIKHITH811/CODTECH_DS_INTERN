#Task 1: Data Pipeline Development

Implemented in: Jupyter Notebook

In this task, I developed an automated data pipeline for preprocessing, transformation, and loading (ETL) using Pandas and Scikit-learn. The notebook includes:

Handling missing values (imputation, removal).

Normalizing and scaling numerical features.

Encoding categorical variables.

Detecting and removing outliers.


The final result is an efficient and reusable data preprocessing pipeline, ensuring high-quality input for machine learning models.
